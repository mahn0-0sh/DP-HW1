{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahn0-0sh/DP-HW1/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2847W-DeU-q8",
        "outputId": "a925ccc8-5708-4c5e-c2ba-317333183b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlearning in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from graphlearning) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from graphlearning) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from graphlearning) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from graphlearning) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->graphlearning) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->graphlearning) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->graphlearning) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->graphlearning) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphlearning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import graphlearning as gl\n",
        "import os"
      ],
      "metadata": {
        "id": "mno3nvp8zEIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset using graphlearning\n",
        "data, lbs = gl.datasets.load('mnist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zpwwDE2Fh1_A",
        "outputId": "d6505616-4d3b-4ecd-ca29-ec9c233f2430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www-users.math.umn.edu/~jwcalder/Data/MNIST_raw.npz to /content/data/mnist_raw.npz...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 1344, in do_open\n",
            "    h.request(req.get_method(), req.selector, req.data, headers,\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1338, in request\n",
            "    self._send_request(method, url, body, headers, encode_chunked)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1384, in _send_request\n",
            "    self.endheaders(body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1333, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1093, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1037, in send\n",
            "    self.connect()\n",
            "  File \"/usr/lib/python3.12/http/client.py\", line 1003, in connect\n",
            "    self.sock = self._create_connection(\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 841, in create_connection\n",
            "    for res in getaddrinfo(host, port, 0, SOCK_STREAM):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/socket.py\", line 978, in getaddrinfo\n",
            "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "socket.gaierror: [Errno -2] Name or service not known\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/graphlearning/utils.py\", line 259, in download_file\n",
            "    urllib.request.urlretrieve(url, file)\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 240, in urlretrieve\n",
            "    with contextlib.closing(urlopen(url, data)) as fp:\n",
            "                            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 215, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 515, in open\n",
            "    response = self._open(req, data)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 532, in _open\n",
            "    result = self._call_chain(self.handle_open, protocol, protocol +\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 492, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 1373, in http_open\n",
            "    return self.do_open(http.client.HTTPConnection, req)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/urllib/request.py\", line 1347, in do_open\n",
            "    raise URLError(err)\n",
            "urllib.error.URLError: <urlopen error [Errno -2] Name or service not known>\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-1352040559.py\", line 2, in <cell line: 0>\n",
            "    data, lbs = gl.datasets.load('mnist')\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/graphlearning/datasets.py\", line 152, in load\n",
            "    utils.download_file(urlpath, dataFile_path)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/graphlearning/utils.py\", line 261, in download_file\n",
            "    sys.exit('Error: Cannot download '+url+'.')\n",
            "SystemExit: Error: Cannot download http://www-users.math.umn.edu/~jwcalder/Data/MNIST_raw.npz.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1345\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m   1004\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0mexceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/graphlearning/utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, file)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' to '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    533\u001b[0m                                   '_open', req)\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno -2] Name or service not known>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1352040559.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the MNIST dataset using graphlearning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mnist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/graphlearning/datasets.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(dataset, metric, labels_only)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0murlpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www-users.math.umn.edu/~jwcalder/Data/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataFile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataFile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/graphlearning/utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, file)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: Cannot download '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: Error: Cannot download http://www-users.math.umn.edu/~jwcalder/Data/MNIST_raw.npz.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming data is a NumPy array from gl.datasets.load('mnist')\n",
        "# data.shape is typically (n_samples, n_features), e.g., (70000, 784) for MNIST\n",
        "\n",
        "# Select the first data point\n",
        "first_point = data[24076]\n",
        "\n",
        "# Select the first 10 data points (including the first point)\n",
        "first_ten_points = data[32613:32614]\n",
        "\n",
        "# Compute L2 distances between the first point and each of the first 10 points\n",
        "distances = np.sqrt(np.sum((first_ten_points - first_point) ** 2, axis=1))\n",
        "\n",
        "# Print the L2 distances\n",
        "print(\"L2 distances between the first data point and the first 10 data points:\")\n",
        "for i, distance in enumerate(distances):\n",
        "    print(f\"Distance to point {i}: {distance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9jByWDuhwSH",
        "outputId": "52ba6400-beb1-4800-a919-9262c9734421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 distances between the first data point and the first 10 data points:\n",
            "Distance to point 0: 10.4672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saoBrROoUkCp",
        "outputId": "28d3b340-432b-4ac2-f0dc-963829e37b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance tensor saved to 'mnist_distances.pt'. Shape: torch.Size([2449965000])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import graphlearning as gl\n",
        "import os\n",
        "\n",
        "# Load the MNIST dataset using graphlearning\n",
        "data, lbs = gl.datasets.load('mnist')\n",
        "\n",
        "# Convert data to a PyTorch tensor\n",
        "X = torch.tensor(data, dtype=torch.float32)  # Shape: (70000, 784)\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Batch size for computing distances (adjust based on GPU memory)\n",
        "batch_size = 5000  # Smaller batch size to fit in GPU memory\n",
        "\n",
        "# Output file for distances\n",
        "output_file = 'mnist_distances.pt'\n",
        "\n",
        "# Remove existing output file if it exists\n",
        "if os.path.exists(output_file):\n",
        "    os.remove(output_file)\n",
        "\n",
        "# Compute pairwise distances in batches\n",
        "distances = []\n",
        "num_samples = X.shape[0]\n",
        "\n",
        "for i in range(0, num_samples, batch_size):\n",
        "    # Get batch of data\n",
        "    X_batch = X[i:i+batch_size].to(device)\n",
        "\n",
        "    # Compute intra-batch distances (i < j within the batch)\n",
        "    if X_batch.shape[0] > 1:  # pdist requires at least 2 samples\n",
        "        intra_batch_dist = torch.pdist(X_batch)\n",
        "        distances.append(intra_batch_dist.cpu())\n",
        "\n",
        "    # Compute inter-batch distances (between current batch and all previous samples)\n",
        "    for j in range(0, i, batch_size):\n",
        "        X_prev = X[j:j+batch_size].to(device)\n",
        "        inter_batch_dist = torch.cdist(X_batch, X_prev).flatten()\n",
        "        distances.append(inter_batch_dist.cpu())\n",
        "\n",
        "    # Free memory\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Concatenate all distances into a single tensor\n",
        "distances = torch.cat(distances)\n",
        "\n",
        "# Save the condensed distance tensor\n",
        "torch.save(distances, output_file)\n",
        "\n",
        "print(f\"Distance tensor saved to '{output_file}'. Shape: {distances.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "i, j = 2076, 5022\n",
        "if i > j:\n",
        "    i, j = j, i  # ensure i < j\n",
        "\n",
        "# Compute index in condensed matrix\n",
        "index = j * (j - 1) // 2 + i\n",
        "\n",
        "# Extract the distance\n",
        "d = distances[index].item()\n",
        "\n",
        "print(f\"Distance between data[2076] and data[5022]: {d}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlS9_vgjomXI",
        "outputId": "07df8254-911c-47f1-d783-3563c55ea89d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between data[2076] and data[5022]: 11.600847244262695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import graphlearning as gl\n",
        "\n",
        "# Load MNIST dataset\n",
        "data, lbs = gl.datasets.load('mnist')   # data is a NumPy array\n",
        "\n",
        "i, j = 2076, 5022\n",
        "\n",
        "# Direct Euclidean distance\n",
        "dist = np.linalg.norm(data[i] - data[j])\n",
        "print(f\"Distance between data[{i}] and data[{j}]: {dist}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAdNmH58qvJQ",
        "outputId": "1c917d1e-94f5-4740-8857-876124c1f0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance between data[2076] and data[5022]: 9.129394077201383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(data, dtype=torch.float32)\n",
        "d = X[2076]-X[5022]\n",
        "a = torch.norm(d, p=2).item()\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot6HpEJfoqUg",
        "outputId": "5d593a7b-31f5-46e3-e064-ed1baf7df2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.12939453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def get_pair_distance_from_file(filename, i, j, num_samples, batch_size):\n",
        "    \"\"\"\n",
        "    Reproduce the exact chunk order used when saving distances:\n",
        "    for each batch b:\n",
        "      1) append pdist(X_b)\n",
        "      2) for each previous batch p < b: append cdist(X_b, X_p).flatten()\n",
        "    Then compute the offset for (i, j) accordingly and return distances[offset].\n",
        "    \"\"\"\n",
        "    if i == j:\n",
        "        return 0.0\n",
        "    if i > j:\n",
        "        i, j = j, i  # ensure i < j\n",
        "\n",
        "    # helper: batch length for batch index b\n",
        "    def batch_len(b):\n",
        "        start = b * batch_size\n",
        "        end = min(num_samples, start + batch_size)\n",
        "        return max(0, end - start)\n",
        "\n",
        "    nb = math.ceil(num_samples / batch_size)\n",
        "\n",
        "    # locate batches and local indices\n",
        "    bi, bj = i // batch_size, j // batch_size\n",
        "    i0, j0 = bi * batch_size, bj * batch_size\n",
        "    i_local, j_local = i - i0, j - j0\n",
        "\n",
        "    # precompute lengths to avoid recomputing\n",
        "    m = [batch_len(b) for b in range(nb)]\n",
        "\n",
        "    # accumulate offset up to the start of batch B:\n",
        "    # sum over k < B of [pdist_len(k) + sum_{p < k} m[k]*m[p]]\n",
        "    def offset_to_batch_start(B):\n",
        "        off = 0\n",
        "        for k in range(B):\n",
        "            # intra (upper-triangular) length for batch k\n",
        "            off += m[k] * (m[k] - 1) // 2\n",
        "            # all inter blocks where current is k and previous is p<k\n",
        "            for p in range(k):\n",
        "                off += m[k] * m[p]\n",
        "        return off\n",
        "\n",
        "    distances = torch.load(filename)\n",
        "\n",
        "    if bi == bj:\n",
        "        # Intra-batch case: use pdist index within this batch, AFTER offsets of earlier batches\n",
        "        off = offset_to_batch_start(bi)\n",
        "        # within-batch pdist index for (i_local, j_local), with i_local < j_local\n",
        "        intra_index = j_local * (j_local - 1) // 2 + i_local\n",
        "        idx = off + intra_index\n",
        "        return distances[idx].item()\n",
        "\n",
        "    else:\n",
        "        # Inter-batch case: value was added when processing the LATER batch (bj),\n",
        "        # comparing X_bj (rows) against earlier batches including bi (columns).\n",
        "        # Order inside that bj-loop:\n",
        "        #   1) pdist(X_bj)\n",
        "        #   2) for p=0..bj-1: cdist(X_bj, X_p).flatten()  (row-major)\n",
        "        off = offset_to_batch_start(bj)\n",
        "\n",
        "        # add intra part for the later batch bj (it is appended before inter blocks)\n",
        "        off += m[bj] * (m[bj] - 1) // 2\n",
        "\n",
        "        # add all inter blocks with earlier batches p < bi\n",
        "        for p in range(bj):\n",
        "            if p == bi:\n",
        "                break\n",
        "            off += m[bj] * m[p]\n",
        "\n",
        "        # now we're inside cdist(X_bj, X_bi).flatten():\n",
        "        # rows correspond to j_local in X_bj, cols correspond to i_local in X_bi\n",
        "        local_index = j_local * m[bi] + i_local\n",
        "        idx = off + local_index\n",
        "        return distances[idx].item()\n",
        "\n",
        "\n",
        "# === Usage for your pair ===\n",
        "filename = \"mnist_distances.pt\"\n",
        "i, j = 2076, 5022\n",
        "\n",
        "# MNIST size from your script\n",
        "num_samples = 70000\n",
        "batch_size = 5000\n",
        "\n",
        "d_from_file = get_pair_distance_from_file(filename, i, j, num_samples, batch_size)\n",
        "print(\"Distance from saved file:\", d_from_file)\n",
        "\n",
        "# (Optional) Cross-check by recomputing directly\n",
        "import graphlearning as gl\n",
        "data, _ = gl.datasets.load('mnist')\n",
        "X = torch.tensor(data, dtype=torch.float32)\n",
        "d_direct = torch.norm(X[i] - X[j], p=2).item()\n",
        "print(\"Direct recompute:\", d_direct)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_89R8L3p3of",
        "outputId": "dcd64bdf-d2eb-406d-c656-6688cf20f5d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance from saved file: 9.12939453125\n",
            "Direct recompute: 9.12939453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(d_direct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dIX1IIZqdal",
        "outputId": "05af2a67-0f38-47db-fc70-a1303b82d152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8217628002166748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[27111] and data[51603]"
      ],
      "metadata": {
        "id": "-V0wYzRyqUzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "def find_min_distance_pair(filename, num_samples, batch_size):\n",
        "    distances = torch.load(filename)\n",
        "\n",
        "    # Find global index of min distance (skip zeros from pdist inside batch)\n",
        "    min_val, min_idx = torch.min(distances, dim=0)\n",
        "    min_val = min_val.item()\n",
        "    min_idx = min_idx.item()\n",
        "\n",
        "    # Helper: batch length for batch index b\n",
        "    def batch_len(b):\n",
        "        start = b * batch_size\n",
        "        end = min(num_samples, start + batch_size)\n",
        "        return max(0, end - start)\n",
        "\n",
        "    nb = math.ceil(num_samples / batch_size)\n",
        "    m = [batch_len(b) for b in range(nb)]\n",
        "\n",
        "    # Offset calc to locate in which block the min_idx falls\n",
        "    def offset_to_batch_start(B):\n",
        "        off = 0\n",
        "        for k in range(B):\n",
        "            off += m[k] * (m[k] - 1) // 2\n",
        "            for p in range(k):\n",
        "                off += m[k] * m[p]\n",
        "        return off\n",
        "\n",
        "    # Find which batch block contains min_idx\n",
        "    bi = bj = None\n",
        "    for B in range(nb):\n",
        "        off = offset_to_batch_start(B)\n",
        "        intra_len = m[B] * (m[B] - 1) // 2\n",
        "        inter_len = sum(m[B] * m[p] for p in range(B))\n",
        "        block_len = intra_len + inter_len\n",
        "\n",
        "        if min_idx < off + block_len:\n",
        "            bj = B  # the \"current\" batch index\n",
        "            break\n",
        "\n",
        "    if bj is None:\n",
        "        raise RuntimeError(\"Index out of range!\")\n",
        "\n",
        "    # Now locate inside batch bj\n",
        "    off = offset_to_batch_start(bj)\n",
        "    intra_len = m[bj] * (m[bj] - 1) // 2\n",
        "\n",
        "    if min_idx < off + intra_len:\n",
        "        # Intra-batch case\n",
        "        rel = min_idx - off\n",
        "        # invert condensed pdist index\n",
        "        # find (i_local, j_local)\n",
        "        j_local = int((1 + math.isqrt(1 + 8*rel)) // 2)\n",
        "        while j_local * (j_local - 1) // 2 > rel:\n",
        "            j_local -= 1\n",
        "        i_local = rel - (j_local * (j_local - 1) // 2)\n",
        "        bi = bj\n",
        "        i = bi * batch_size + i_local\n",
        "        j = bj * batch_size + j_local\n",
        "    else:\n",
        "        # Inter-batch case\n",
        "        rel = min_idx - off - intra_len\n",
        "        # Figure out which previous batch p\n",
        "        cum = 0\n",
        "        for p in range(bj):\n",
        "            block_size = m[bj] * m[p]\n",
        "            if rel < cum + block_size:\n",
        "                bi = p\n",
        "                local_rel = rel - cum\n",
        "                j_local = local_rel // m[p]\n",
        "                i_local = local_rel % m[p]\n",
        "                i = bi * batch_size + i_local\n",
        "                j = bj * batch_size + j_local\n",
        "                break\n",
        "            cum += block_size\n",
        "\n",
        "    return i, j, min_val\n",
        "\n",
        "\n",
        "# === Usage ===\n",
        "filename = \"mnist_distances.pt\"\n",
        "num_samples = 70000\n",
        "batch_size = 5000\n",
        "\n",
        "i, j, d = find_min_distance_pair(filename, num_samples, batch_size)\n",
        "print(f\"Minimum distance is {d} between data[{i}] and data[{j}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFKUxRhtqN3U",
        "outputId": "2a1a2b13-53e7-4fb5-e0f3-2c824052fb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum distance is 0.8217760324478149 between data[27111] and data[51603]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "# Load the distance tensor\n",
        "output_file = 'mnist_distances.pt'\n",
        "distances = torch.load(output_file)\n",
        "\n",
        "# Verify the shape\n",
        "N = 70000  # Number of samples in MNIST\n",
        "expected_size = (N * (N - 1)) // 2\n",
        "if distances.shape[0] != expected_size:\n",
        "    raise ValueError(f\"Unexpected distance tensor size: {distances.shape[0]}, expected {expected_size}\")\n",
        "\n",
        "# Find the minimum distance (all distances should be non-zero)\n",
        "min_distance, min_idx = torch.min(distances, dim=0)\n",
        "min_distance = min_distance.item()\n",
        "min_idx = min_idx.item()\n",
        "\n",
        "# Function to map condensed index to pair (i, j)\n",
        "def condensed_idx_to_pair(k, N):\n",
        "    # Find i such that k falls in row i of the upper triangle\n",
        "    i = 0\n",
        "    pairs_before_i = 0\n",
        "    while True:\n",
        "        pairs_in_row_i = N - i - 1\n",
        "        if pairs_before_i <= k < pairs_before_i + pairs_in_row_i:\n",
        "            j = k - pairs_before_i + i + 1\n",
        "            return i, j\n",
        "        pairs_before_i += pairs_in_row_i\n",
        "        i += 1\n",
        "        if i >= N:\n",
        "            raise ValueError(\"Invalid condensed index\")\n",
        "\n",
        "# Get the pair of indices\n",
        "i, j = condensed_idx_to_pair(min_idx, N)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Minimum non-zero distance: {min_distance}\")\n",
        "print(f\"Indices of the two data points in 'data': ({i}, {j})\")"
      ],
      "metadata": {
        "id": "1XgxUYh1jc4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6be60b-1ab1-42a0-9024-53ad5fcd4bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum non-zero distance: 0.8217760324478149\n",
            "Indices of the two data points in 'data': (24076, 32614)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "# Load the distance tensor\n",
        "output_file = 'mnist_distances.pt'\n",
        "distances = torch.load(output_file)\n",
        "\n",
        "# Number of samples\n",
        "N = 70000\n",
        "\n",
        "# Verify the shape of the distance tensor\n",
        "expected_size = (N * (N - 1)) // 2\n",
        "if distances.shape[0] != expected_size:\n",
        "    raise ValueError(f\"Unexpected distance tensor size: {distances.shape[0]}, expected {expected_size}\")\n",
        "\n",
        "# Find the minimum distance\n",
        "min_distance, min_idx = torch.min(distances, dim=0)\n",
        "min_distance = min_distance.item()\n",
        "min_idx = min_idx.item()\n",
        "\n",
        "# Corrected function to map condensed index to pair (i, j)\n",
        "def condensed_idx_to_pair(k, N):\n",
        "    # Use quadratic formula to find i\n",
        "    # Solve: i (2N - i - 1) / 2 <= k\n",
        "    # This is a quadratic inequality: i^2 - (2N-1)i + 2k <= 0\n",
        "    # We want the largest integer i satisfying this\n",
        "    a = 1\n",
        "    b = -(2 * N - 1)\n",
        "    c = 2 * k\n",
        "    discriminant = b**2 - 4 * a * c\n",
        "    i = int((-b - math.sqrt(discriminant)) / (2 * a))  # Take the smaller root and floor it\n",
        "    if i < 0 or i >= N:\n",
        "        i = 0  # Handle edge case for k=0\n",
        "    # Compute the number of pairs before row i\n",
        "    pairs_before_i = (i * (2 * N - i - 1)) // 2\n",
        "    # Compute j\n",
        "    j = k - pairs_before_i + i + 1\n",
        "    if j >= N or j <= i:\n",
        "        raise ValueError(f\"Invalid indices computed: i={i}, j={j}, k={k}, N={N}\")\n",
        "    return i, j\n",
        "\n",
        "# Get the pair of indices\n",
        "i, j = condensed_idx_to_pair(min_idx, N)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Minimum non-zero distance: {min_distance}\")\n",
        "print(f\"Indices of the two data points in 'data': ({i}, {j})\")\n",
        "\n",
        "# Optional: Verify the distance by recomputing\n",
        "import graphlearning as gl\n",
        "import numpy as np\n",
        "data, _ = gl.datasets.load('mnist')\n",
        "X = np.array(data, dtype=np.float32)\n",
        "computed_distance = np.sqrt(np.sum((X[i] - X[j])**2))\n",
        "print(f\"Verification: Computed distance between points {i} and {j}: {computed_distance}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02MFG3qOoBRE",
        "outputId": "3d8b6fae-e2cf-42c9-a9e3-31a85c1f96d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum non-zero distance: 0.8217760324478149\n",
            "Indices of the two data points in 'data': (24076, 32614)\n",
            "Verification: Computed distance between points 24076 and 32614: 12.193633079528809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "output_file = 'mnist_distances.pt'\n",
        "drive_folder = '/content/drive/My Drive/MNIST_Distance'  # Change this path as needed\n",
        "drive_file_path = os.path.join(drive_folder, output_file)\n",
        "\n",
        "# Create Drive folder if it doesn't exist\n",
        "if not os.path.exists(drive_folder):\n",
        "    os.makedirs(drive_folder)\n",
        "\n",
        "\n",
        "print(f\"Distance tensor saved.\")\n",
        "\n",
        "# Upload to Google Drive\n",
        "try:\n",
        "    if os.path.exists(output_file):\n",
        "        shutil.copy(output_file, drive_file_path)\n",
        "        print(f\"File uploaded to Google Drive at '{drive_file_path}'\")\n",
        "    else:\n",
        "        print(f\"Error: Local file '{output_file}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading to Google Drive: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "lM_Pafxcp570",
        "outputId": "7534b634-c1cc-4a35-e378-6b8e2db4f825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2891691785.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URxb96C1CXZS",
        "outputId": "70ab8754-5cc6-4d80-9ce1-dc799ccb2a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# Define paths\n",
        "drive_file_path = '/content/drive/My Drive/MNIST_Distance/mnist_distances.pt'  # Path to file in Google Drive\n",
        "local_file_path = 'mnist_distances.pt'  # Destination path in Colab\n",
        "\n",
        "# Check if the file exists in Google Drive\n",
        "if os.path.exists(drive_file_path):\n",
        "    # Copy the file to Colab working directory\n",
        "    try:\n",
        "        shutil.copy(drive_file_path, local_file_path)\n",
        "        print(f\"File downloaded from Google Drive to '{local_file_path}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading file from Google Drive: {str(e)}\")\n",
        "else:\n",
        "    print(f\"Error: File '{drive_file_path}' not found in Google Drive.\")\n",
        "# Load the file as a PyTorch tensor\n",
        "try:\n",
        "    if os.path.exists(local_file_path):\n",
        "        distances = torch.load(local_file_path)\n",
        "        print(f\"Distance tensor loaded successfully. Shape: {distances.shape}\")\n",
        "    else:\n",
        "        print(f\"Error: Local file '{local_file_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {str(e)}\")"
      ],
      "metadata": {
        "id": "9DhKtSC-tIQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63075cd4-1e42-453a-f3f1-fd7fc4dfebc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File downloaded from Google Drive to 'mnist_distances.pt'\n",
            "Distance tensor loaded successfully. Shape: torch.Size([2449965000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ngbH8J6cHYh",
        "outputId": "95017ad3-899c-4b94-b1be-a25a3da4c55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gmbk-b-EuHPi",
        "outputId": "4a40d161-736b-49cd-86ce-ea2342ea58c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIpxqeaS8Xa8",
        "outputId": "7f2adf3e-2ce7-457c-dec1-892667668fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([70000, 70000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the pre-saved distances from the file\n",
        "distances_file = 'mnist_distances.pt'\n",
        "distances = torch.load(distances_file, mmap=True)  # Keeping it as a tensor"
      ],
      "metadata": {
        "id": "AyRB8KQiwxKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "def create_adjacency(epsilon, distances, num_samples=70000, batch_size=5000):\n",
        "    \"\"\"\n",
        "    Constructs a sparse adjacency matrix in CSR format for an undirected graph\n",
        "    from a distance array stored in custom chunk order (intra-batch then inter-batch).\n",
        "    Uses scipy.sparse.csr_matrix on CPU, then converts to PyTorch sparse_csr_tensor.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    epsilon : float\n",
        "        Distance threshold for edge creation.\n",
        "    distances : torch.Tensor\n",
        "        1D tensor of pairwise distances (on CPU) saved in custom batch order.\n",
        "    num_samples : int\n",
        "        Number of samples in the dataset (default=70000 for MNIST).\n",
        "    batch_size : int\n",
        "        Batch size used when generating the distances.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    tuple\n",
        "        - adj_tensor (torch.sparse_csr_tensor): Sparse adjacency matrix in CSR format.\n",
        "        - num_edges (int): Number of undirected edges in the graph.\n",
        "    \"\"\"\n",
        "\n",
        "    # Version warning\n",
        "    if torch.__version__ < '1.13.0':\n",
        "        warnings.warn(f\"PyTorch version {torch.__version__} may have sparse CSR issues. Upgrade to >=1.13.0 recommended.\")\n",
        "\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    nbatches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    row_indices = []\n",
        "    col_indices = []\n",
        "    num_edges = 0\n",
        "    offset = 0  # pointer inside distances\n",
        "\n",
        "    for bi in tqdm(range(nbatches), desc=\"Processing batches\"):\n",
        "        start_i = bi * batch_size\n",
        "        end_i = min(start_i + batch_size, num_samples)\n",
        "        bs_i = end_i - start_i\n",
        "\n",
        "        # --- Intra-batch ---\n",
        "        if bs_i > 1:\n",
        "            num_intra = bs_i * (bs_i - 1) // 2\n",
        "            intra_d = distances[offset:offset + num_intra]\n",
        "            offset += num_intra\n",
        "\n",
        "            mask = intra_d < epsilon\n",
        "            if mask.any():\n",
        "                intra_indices = torch.triu_indices(bs_i, bs_i, offset=1)\n",
        "                ii = intra_indices[0][mask] + start_i\n",
        "                jj = intra_indices[1][mask] + start_i\n",
        "\n",
        "                row_indices.append(ii.numpy())\n",
        "                col_indices.append(jj.numpy())\n",
        "                row_indices.append(jj.numpy())\n",
        "                col_indices.append(ii.numpy())\n",
        "                num_edges += mask.sum().item()\n",
        "\n",
        "        # --- Inter-batch (bi vs all earlier batches) ---\n",
        "        for bj in range(bi):\n",
        "            start_j = bj * batch_size\n",
        "            end_j = min(start_j + batch_size, num_samples)\n",
        "            bs_j = end_j - start_j\n",
        "\n",
        "            num_inter = bs_i * bs_j\n",
        "            inter_d = distances[offset:offset + num_inter].view(bs_i, bs_j)\n",
        "            offset += num_inter\n",
        "\n",
        "            mask = inter_d < epsilon\n",
        "            if mask.any():\n",
        "                inter_indices = torch.nonzero(mask, as_tuple=False)\n",
        "                ii = inter_indices[:, 0] + start_i\n",
        "                jj = inter_indices[:, 1] + start_j\n",
        "\n",
        "                row_indices.append(ii.numpy())\n",
        "                col_indices.append(jj.numpy())\n",
        "                row_indices.append(jj.numpy())\n",
        "                col_indices.append(ii.numpy())\n",
        "                num_edges += inter_indices.size(0)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # --- Build scipy CSR ---\n",
        "    if row_indices:\n",
        "        row_indices = np.concatenate(row_indices)\n",
        "        col_indices = np.concatenate(col_indices)\n",
        "        data = np.ones(len(row_indices), dtype=np.bool_)\n",
        "\n",
        "        scipy_csr = csr_matrix((data, (row_indices, col_indices)),\n",
        "                               shape=(num_samples, num_samples))\n",
        "        print(f\"Created scipy CSR matrix: nnz={scipy_csr.nnz}\")\n",
        "\n",
        "        # --- Convert to PyTorch sparse CSR ---\n",
        "        indptr = torch.tensor(scipy_csr.indptr, dtype=torch.int64, device=device)\n",
        "        indices = torch.tensor(scipy_csr.indices, dtype=torch.int64, device=device)\n",
        "        data = torch.tensor(scipy_csr.data, dtype=torch.bool, device=device)\n",
        "\n",
        "        adj_tensor = torch.sparse_csr_tensor(\n",
        "            indptr,\n",
        "            indices,\n",
        "            data,\n",
        "            size=(num_samples, num_samples),\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        print(f\"Created PyTorch CSR tensor: layout={adj_tensor.layout}, \"\n",
        "              f\"size={adj_tensor.shape}, nnz={adj_tensor._nnz()}\")\n",
        "    else:\n",
        "        print(\"No edges found, returning empty CSR tensor\")\n",
        "        adj_tensor = torch.sparse_csr_tensor(\n",
        "            torch.zeros(num_samples + 1, dtype=torch.int64, device=device),\n",
        "            torch.empty(0, dtype=torch.int64, device=device),\n",
        "            torch.empty(0, dtype=torch.bool, device=device),\n",
        "            size=(num_samples, num_samples),\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    return adj_tensor, scipy_csr, num_edges\n"
      ],
      "metadata": {
        "id": "RmDtnsIJsPBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del adj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "O8kRALHCvWPb",
        "outputId": "58d72ee4-58a4-44a6-a80e-98c06cd50ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'adj' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1471267928.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'adj' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6t6t-rIexfO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(scipy_csr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9drtwcdx0EV",
        "outputId": "5de6202f-bab0-4dac-d3d7-7634e39f2150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 70000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def is_graph_connected_sparse(adj_tensor):\n",
        "    \"\"\"\n",
        "    Efficient connectivity check for large sparse CSR graph.\n",
        "    Shows BFS iterations with tqdm.\n",
        "    \"\"\"\n",
        "    if adj_tensor.layout != torch.sparse_csr:\n",
        "        raise ValueError(f\"Input must be CSR sparse tensor, got {adj_tensor.layout}\")\n",
        "\n",
        "    n = adj_tensor.size(0)\n",
        "    if n == 0:\n",
        "        return True\n",
        "\n",
        "    crow = adj_tensor.crow_indices()\n",
        "    col = adj_tensor.col_indices()\n",
        "\n",
        "    visited = torch.zeros(n, dtype=torch.bool, device=adj_tensor.device)\n",
        "    queue = torch.tensor([0], dtype=torch.int64, device=adj_tensor.device)\n",
        "    visited[0] = True\n",
        "\n",
        "    pbar = tqdm(desc=\"BFS iterations\", unit=\"level\")\n",
        "\n",
        "    while queue.numel() > 0:\n",
        "        # gather row ranges for all nodes in queue\n",
        "        starts = crow[queue]\n",
        "        ends = crow[queue + 1]\n",
        "\n",
        "        # collect all neighbors in one big chunk\n",
        "        all_neighbors = [col[s:e] for s, e in zip(starts.tolist(), ends.tolist())]\n",
        "        if not all_neighbors:\n",
        "            break\n",
        "        neighbors = torch.cat(all_neighbors)\n",
        "\n",
        "        # filter new ones\n",
        "        mask = ~visited[neighbors]\n",
        "        neighbors = neighbors[mask]\n",
        "\n",
        "        visited[neighbors] = True\n",
        "        queue = torch.unique(neighbors)\n",
        "\n",
        "        pbar.update(1)   # update per BFS level\n",
        "\n",
        "    pbar.close()\n",
        "    return visited.all().item()\n"
      ],
      "metadata": {
        "id": "ng6a86BbwEUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = is_graph_connected_sparse(adj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU7bpEJNwVje",
        "outputId": "25d5cac7-e90f-4372-e895-5583a8958ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BFS iterations: 6level [00:00, 11.45level/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx5On1CZwZrK",
        "outputId": "422f6197-a59f-4043-c91b-6c1f79081896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del adj, scipy_csr"
      ],
      "metadata": {
        "id": "0q4ukfoD84Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 8.478\n",
        "adj, scipy_csr, num = create_adjacency(epsilon, distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSi25FNwsVes",
        "outputId": "36b97572-ac6c-4181-86e0-0e007a35820f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|| 14/14 [00:07<00:00,  1.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created scipy CSR matrix: nnz=541146740\n",
            "Created PyTorch CSR tensor: layout=torch.sparse_csr, size=torch.Size([70000, 70000]), nnz=541146740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3171753264.py:112: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  adj_tensor = torch.sparse_csr_tensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scipy_csr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DvusHnGyRW_",
        "outputId": "64acd663-e7ff-4670-c371-94573ce0b9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 70000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(scipy_csr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytVfCmF5yWMn",
        "outputId": "959492ae-3caf-463b-ada3-8a9202b9eeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'bool'\n",
            "\twith 2570 stored elements and shape (1, 70000)>\n",
            "  Coords\tValues\n",
            "  (0, 10)\tTrue\n",
            "  (0, 41)\tTrue\n",
            "  (0, 43)\tTrue\n",
            "  (0, 49)\tTrue\n",
            "  (0, 70)\tTrue\n",
            "  (0, 74)\tTrue\n",
            "  (0, 125)\tTrue\n",
            "  (0, 130)\tTrue\n",
            "  (0, 132)\tTrue\n",
            "  (0, 135)\tTrue\n",
            "  (0, 195)\tTrue\n",
            "  (0, 219)\tTrue\n",
            "  (0, 258)\tTrue\n",
            "  (0, 291)\tTrue\n",
            "  (0, 321)\tTrue\n",
            "  (0, 332)\tTrue\n",
            "  (0, 346)\tTrue\n",
            "  (0, 396)\tTrue\n",
            "  (0, 403)\tTrue\n",
            "  (0, 407)\tTrue\n",
            "  (0, 420)\tTrue\n",
            "  (0, 425)\tTrue\n",
            "  (0, 474)\tTrue\n",
            "  (0, 514)\tTrue\n",
            "  (0, 543)\tTrue\n",
            "  :\t:\n",
            "  (0, 69445)\tTrue\n",
            "  (0, 69465)\tTrue\n",
            "  (0, 69474)\tTrue\n",
            "  (0, 69523)\tTrue\n",
            "  (0, 69524)\tTrue\n",
            "  (0, 69536)\tTrue\n",
            "  (0, 69545)\tTrue\n",
            "  (0, 69559)\tTrue\n",
            "  (0, 69561)\tTrue\n",
            "  (0, 69579)\tTrue\n",
            "  (0, 69581)\tTrue\n",
            "  (0, 69582)\tTrue\n",
            "  (0, 69583)\tTrue\n",
            "  (0, 69610)\tTrue\n",
            "  (0, 69698)\tTrue\n",
            "  (0, 69830)\tTrue\n",
            "  (0, 69847)\tTrue\n",
            "  (0, 69853)\tTrue\n",
            "  (0, 69854)\tTrue\n",
            "  (0, 69863)\tTrue\n",
            "  (0, 69870)\tTrue\n",
            "  (0, 69882)\tTrue\n",
            "  (0, 69883)\tTrue\n",
            "  (0, 69892)\tTrue\n",
            "  (0, 69893)\tTrue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.csgraph import connected_components\n",
        "print(epsilon)\n",
        "n_components, labels = connected_components(scipy_csr, directed=False)\n",
        "print(\"Number of components:\", n_components)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDnxUij1_zN_",
        "outputId": "e6c9ff9c-7b6f-491c-88ad-d7205da114a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.478\n",
            "Number of components: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse.csgraph import connected_components\n",
        "print(epsilon)\n",
        "n_components, labels = connected_components(scipy_csr, directed=False)\n",
        "print(\"Number of components:\", n_components)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnDCeY98w9dh",
        "outputId": "c5f99286-97a8-49ae-edba-ce5944d790b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.48\n",
            "Number of components: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(adj.shape)\n",
        "print(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ID8KyUP8uEfT",
        "outputId": "a64d7c95-8e38-460a-b5c3-2e681d309211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([70000, 70000])\n",
            "467313380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(distances.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltGtO01pJNI8",
        "outputId": "cc29655c-6cb5-4aa5-8df0-a45a43347ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2449965000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mKi_4Yjyk7gA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1aq-Z-I0UAAGJrpn6OzNb0jYX4Wrdtkqu",
      "authorship_tag": "ABX9TyMSWjKdUzEGCnuZvmp+x5St",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}